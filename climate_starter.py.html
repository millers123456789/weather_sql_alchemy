
# coding: utf-8

# In[1]:


get_ipython().run_line_magic('matplotlib', 'inline')
from matplotlib import style
style.use('fivethirtyeight')
import matplotlib.pyplot as plt


# In[2]:


import numpy as np
import pandas as pd


# In[3]:


import datetime as dt


# # Reflect Tables into SQLAlchemy ORM

# In[4]:


# Python SQL toolkit and Object Relational Mapper
import sqlalchemy
from sqlalchemy.ext.automap import automap_base
from sqlalchemy.orm import Session
from sqlalchemy import create_engine, func


# In[5]:


engine = create_engine("sqlite:///Resources/hawaii.sqlite")


# In[6]:


# reflect an existing database into a new model
Base = automap_base()
# reflect the tables
Base.prepare(engine, reflect=True)


# In[7]:


# We can view all of the classes that automap found
Base.classes.keys()


# In[8]:


# Save references to each table
Measurement = Base.classes.measurement
Station = Base.classes.station


# In[9]:


# Create our session (link) from Python to the DB
session = Session(engine)


# In[13]:


# I would like to see the data first in a data frame
#hawaii = session.query().all()
hawaii = pd.read_csv("Resources/hawaii_measurements.csv")
hawaii.head()
hawaii


# # Exploratory Climate Analysis

# In[215]:


# Design a query to retrieve the last 12 months of precipitation data and plot the results
query_date = dt.date(2017, 8, 23) - dt.timedelta(days=365)

#print("{} was the level of precipitation last year".format(rain_2017))
# Calculate the date 1 year ago from the last data point in the database

#print("Query Date: ", query_date)
# Perform a query to retrieve the data and precipitation scores

# Save the query results as a Pandas DataFrame and set the index to the date column

# Sort the dataframe by date

# Use Pandas Plotting with Matplotlib to plot the data
#rain_2017_df.head(100)


# In[71]:


# Design a query to retrieve all of precipitation data and plot the results
past_rain.describe()


# In[269]:


#plot all the rain data
rain = session.query(Measurement.prcp,Measurement.date).    filter(Measurement.date >= query_date).order_by(Measurement.date).all()
#lets make a list 
rain_df = pd.DataFrame(np.array(rain))
past_rain_df = pd.to_numeric(rain_df[0])
rain_df.head()
rain_df.plot.line(1,0)
plt.title("Precipitation")
plt.ylabel("Inches of precipitation")
plt.xlabel("Date")
plt.grid(True)
plt.savefig("Precipitation_last_year.png")

#rain_df = pd.DataFrame(rain)


# ![precipitation](Images/precipitation.png)

# In[ ]:


# Use Pandas to calcualte the summary statistics for the precipitation data
past_rain.describe()


# ![describe](Images/describe.png)

# In[100]:


# Design a query to show how many stations are available in this dataset?
station_2017 = session.query(Measurement.station,Measurement.date, Measurement.tobs).    filter(Measurement.date >= query_date).all()
station_2017_df = pd.DataFrame(np.array(station_2017))
station_2017_df.head()


# In[217]:


#count the number of occourences of unique stations 
location_station = session.query(Measurement).group_by(Measurement.station).count()
print("There are {} stations.".format(location_station))


# In[221]:


#I have to do a list station activity
weather_data = session.query(Measurement.station, func.count(Measurement.tobs)).group_by(Measurement.station).order_by(func.count(Measurement.tobs).desc()).all()

for station, count in weather_data:
    print("Station", station, "has",count, "weather records")


# In[226]:


# What are the most active stations? (i.e. what stations have the most rows)?
# List the stations and the counts in descending order.
USC_most = session.query(Measurement.tobs).filter(Measurement.station == "USC00519281", Measurement.station == Station.station, Measurement.date > query_date).all()
USC_most_df = pd.DataFrame(USC_most)
USC_most_df.head()
USC_most_df["tobs"].max()


# In[ ]:


#Max temp
USC_most_df["tobs"].max()


# In[227]:


#min temp
USC_most_df["tobs"].min()


# In[116]:


# Using the station id from the previous query, calculate the lowest temperature recorded, 
# highest temperature recorded, and average temperature most active station?
USC.head()
temp_most_active_station = USC[2]
past_station = pd.to_numeric(temp_most_active_station)

print(past_station.min())
print(past_station.max())
print(past_station.mean())
#print(temp_most_active_station.mean())


# In[236]:


#we want to count the frequency of the temperatures displayed for this station
temps = [temp[0] for temp in USC_most]
temps


# In[268]:


#bin
#split data into three groups 
plt.hist(temps, bins=12)
plt.title("Frequency of temperature in USC00519281")
plt.ylabel("Frequency")
plt.xlabel("Temperature")
plt.grid(True)
plt.savefig("Frequency_of_temp.png")


# In[178]:





# In[ ]:


# Choose the station with the highest number of temperature observations.
# Query the last 12 months of temperature observation data for this station and plot the results as a histogram


# ![precipitation](Images/station-histogram.png)

# In[185]:


# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' 
# and return the minimum, average, and maximum temperatures for that range of dates
def calc_temps(start_date, end_date):
    """TMIN, TAVG, and TMAX for a list of dates.
    
    Args:
        start_date (string): A date string in the format %Y-%m-%d
        end_date (string): A date string in the format %Y-%m-%d
        
    Returns:
        TMIN, TAVE, and TMAX
    """
    
    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()

# function usage example
print(calc_temps('2012-02-28', '2012-03-05'))


# In[188]:


# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax 
# for your trip using the previous year's data for those same dates.
#all you have to do is plug in the the most recent date and one year before that to get this data
print(calc_temps('2016-08-23', '2017-08-23'))
py = calc_temps('2016-08-23', '2017-08-23')


# In[270]:


# Plot the results from your previous query as a bar chart. 
# Use "Trip Avg Temp" as your Title
# Use the average temperature for the y value
# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)
py_df = pd.DataFrame([58.0, 74.59058295964, 87.0])
y_values = 74.59
yerr_total = 87.0-58
x_value = 1
#yerr_bottom = 74.59058295964- 58
#py_df
plt.bar(x_value, y_values, yerr=yerr_total)
plt.title("Trip Avg Temp")
plt.ylabel("average temperature")
plt.xlabel("Generic")
plt.grid(True)
#save fig by calling on pyber results where you saved before
plt.savefig("Trip_average.png")


# In[265]:


# Calculate the rainfall per weather station for your trip dates using the previous year's matching dates.
# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation
query_date = dt.date(2017, 8, 23) - dt.timedelta(days=365)
rain_2017 = session.query(Measurement.prcp,Measurement.date,Measurement.station).    filter(Measurement.date >= query_date).all()
sel = [Station.latitude, Station.name, Station.longitude, Station.elevation,Station.station, Measurement.prcp, Measurement.date,Measurement.station]
same_station = session.query(*sel).filter(Measurement.station == Station.station).filter(Measurement.date >= query_date).group_by(Measurement.station).order_by(func.sum(Measurement.prcp).desc()).all()
station = session.query(Station.latitude,Station.longitude,Station.name)
print(same_station)



# ## Optional Challenge Assignment

# In[ ]:


# Create a query that will calculate the daily normals 
# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)

def daily_normals(date):
    """Daily Normals.
    
    Args:
        date (str): A date string in the format '%m-%d'
        
    Returns:
        A list of tuples containing the daily normals, tmin, tavg, and tmax
    
    """
    
    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]
    return session.query(*sel).filter(func.strftime("%m-%d", Measurement.date) == date).all()
    
daily_normals("01-01")


# In[ ]:


# calculate the daily normals for your trip
# push each tuple of calculations into a list called `normals`

# Set the start and end date of the trip

# Use the start and end date to create a range of dates

# Stip off the year and save a list of %m-%d strings

# Loop through the list of %m-%d strings and calculate the normals for each date


# In[ ]:


# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index


# In[ ]:


# Plot the daily normals as an area plot with `stacked=False`

